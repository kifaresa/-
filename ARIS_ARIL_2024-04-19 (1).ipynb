{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIS/ARIL Working File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\" # you may have to comment this out if plotly isn't installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-04-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Data from CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Picking Data\n",
    "df_OrderData_CasePick = pd.read_csv(\"ARIS_ARIL_Data/CasePicking/orderlines.csv\", sep=\";\") # set path and file name \n",
    "df_MasterData_CasePick = pd.read_csv(\"ARIS_ARIL_Data/CasePicking/itemmaster.csv\", sep=\";\") # set path and file name \n",
    "\n",
    "# e-com Data\n",
    "data_path_eCom = 'ARIS_ARIL_Data/e-com/' # set path and file name \n",
    "File_ItemMaster_eCom = 'item_master.csv' # set path and file name \n",
    "File_OrderData_eCom = 'orderline_data.csv' # set path and file name \n",
    "\n",
    "df_MasterData_eCom = pd.read_csv(data_path_eCom+File_ItemMaster_eCom, sep='\\t')\n",
    "df_OrderData_eCom = pd.read_csv(data_path_eCom+File_OrderData_eCom, sep='\\t', parse_dates = ['orderTime']) # here we parse the column 'orderTime' directly to DateTime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Column Names\n",
    "Defining variables for column names allows more convenient access to columns, especially when using column names as arguments in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_length = 'depth'\n",
    "col_width = 'width'\n",
    "col_height = 'height'\n",
    "col_weight = 'weight'\n",
    "\n",
    "col_ItemID = 'itemID'\n",
    "col_OrderID = 'orderID'\n",
    "\n",
    "col_OrderDate = \"OrderDate\"\n",
    "col_OrderWeekDay = \"OrderWeekDay\"\n",
    "col_OrderHour = \"OrderHour\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data Before Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Picking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting Data Types\n",
    "df_OrderData_CasePick[\"orderID\"] = df_OrderData_CasePick[\"orderID\"].astype(str)\n",
    "df_OrderData_CasePick[\"customerID\"] = df_OrderData_CasePick[\"customerID\"].astype(str)\n",
    "df_OrderData_CasePick[\"orderTime\"] = pd.to_datetime(df_OrderData_CasePick[\"orderTime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e-com Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_OrderData_eCom[col_OrderID] = df_OrderData_eCom[col_OrderID].astype(str)\n",
    "df_OrderData_eCom[col_OrderDate] = df_OrderData_eCom['orderTime'].dt.date\n",
    "df_OrderData_eCom[col_OrderWeekDay] = df_OrderData_eCom['orderTime'].dt.day_name()\n",
    "df_OrderData_eCom[col_OrderHour] = df_OrderData_eCom['orderTime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_CasePick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKU Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MasterData_CasePick[\"itemID\"].nunique()\n",
    "df_OrderData_CasePick[\"itemID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_CasePick['orderTime'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "### Case Picking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code we took from ChatGPT\n",
    "# Replace 0 values with NaN in the specified columns\n",
    "df_MasterData_CasePick[['depth', 'width', 'height', 'weight']] = df_MasterData_CasePick[['depth', 'width', 'height', 'weight']].replace(0, pd.NA)\n",
    "\n",
    "# Filter out rows where any of the specified columns have NaN values\n",
    "df_MasterData_CasePick = df_MasterData_CasePick.dropna(subset=['depth', 'width', 'height', 'weight'])\n",
    "\n",
    "# Optionally, you can also filter out nonsensical values based on some threshold\n",
    "# For example, if you consider negative values as wrong for dimensions:\n",
    "df_MasterData_CasePick = df_MasterData_CasePick[(df_MasterData_CasePick['depth'] > 0) & (df_MasterData_CasePick['width'] > 0) & (df_MasterData_CasePick['height'] > 0) & (df_MasterData_CasePick['weight'] > 0)]\n",
    "\n",
    "# Now df_MasterData_CasePick contains only rows where length, width, height, and weight are not 0, empty, or nonsensical\n",
    "\n",
    "# If you want to reset the index of the filtered DataFrame\n",
    "df_MasterData_CasePick.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now df_MasterData_CasePick is your DataFrame with the desired filtering applied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Dimensions in Item Master to Detect Implausible Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MasterData_CasePick[['depth', 'width', 'height']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_MasterData_CasePick[['depth', 'width', 'height']].plot.box()\n",
    "df_MasterData_eCom[['depth', 'width', 'height']].plot.box()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MasterData_CasePick[[col_ItemID,'depth', 'width', 'height']].sort_values(by='height', ascending=False)\n",
    "df_MasterData_CasePick_Ugly = df_MasterData_CasePick[df_MasterData_CasePick['height'] > 1000] # Note: Here we are only checking for height. We should include the other dimensions, too. Please try this yourself.\n",
    "df_MasterData_CasePick_Ugly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how many orderlines are created with items with extreme dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_CasePick_Ugly = pd.merge(df_OrderData_CasePick, df_MasterData_CasePick_Ugly, on=col_ItemID, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLpD_CasePick_Ugly = df_OrderData_CasePick_Ugly.groupby('orderTime').size().reset_index(name='Count_OL')\n",
    "df_OLpD_CasePick_Ugly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e-com Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders per Day\n",
    "df_OpD_eCom = df_OrderData_eCom.groupby(col_OrderDate)[col_OrderID].nunique().reset_index(name='OpD')\n",
    "df_OpD_eCom.plot.bar(x=col_OrderDate, y='OpD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orderlines per Day\n",
    "df_OLpD = df_OrderData_eCom.groupby(col_OrderDate).size().reset_index(name='OLpD')\n",
    "df_OLpD\n",
    "#df_OLpD.plot.bar(x=col_OrderDate, y='OLpD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKUs per Day\n",
    "df_SKUspD = df_OrderData_eCom.groupby(col_OrderDate)[col_ItemID].nunique().reset_index(name='SKUs_p_D')\n",
    "df_SKUspD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SKUs_pH_eCom = df_OrderData_eCom.groupby([col_OrderWeekDay,col_OrderHour])[col_ItemID].nunique().reset_index()\n",
    "df_SKUs_pH_eCom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OpWeekDay_eCom = df_OrderData_eCom.groupby(col_OrderWeekDay)[col_OrderID].nunique().reset_index()\n",
    "df_OpWeekDay_eCom.plot.bar(x=col_OrderWeekDay, y=col_OrderID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e-com Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-com data\n",
    "df_OL_p_O_eCom = df_OrderData_eCom.groupby(col_OrderID).size().reset_index(name='OL_p_O')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Orders with \"Many\" orderlines (> n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "df_OL_p_O_High = df_OL_p_O_eCom[df_OL_p_O_eCom['OL_p_O'] >= 50]\n",
    "df_OL_p_O_High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OL_p_O_eCom['OL_p_O'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_eCom_LargeOrders = pd.merge(df_OL_p_O_High, df_OrderData_eCom, on=col_OrderID, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_eCom_LargeOrders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_eCom_LargeOrders.groupby(col_OrderDate)[col_OrderID].nunique().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Orderlines with High Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_eCom_LargeQty = df_OrderData_eCom[df_OrderData_eCom['qty']>50].groupby(col_OrderDate)['qty'].size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OrderData_eCom_LargeQty.plot.bar(x=col_OrderDate, y='qty')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
